"""
AIè‡ªåŠ¨åŒ–æœåŠ¡
æ•´åˆå›¾åƒè¯†åˆ«ã€AIåˆ†æã€åŠ¨ä½œè§£æå’Œä»£ç ç”Ÿæˆçš„å®Œæ•´å·¥ä½œæµ
"""

import os
import time
import json
import logging
from typing import Dict, Any, List, Optional, Tuple
from PIL import Image, ImageDraw
import pyautogui
import pyperclip
from datetime import datetime
import io

# å¯¼å…¥æ–°çš„å›¾åƒå·¥å…·
from utils.image_utils import image_to_base64

# å¯¼å…¥DAO
from database.dao import AnalysisLogDAO
from database.models import AnalysisLog

# å¯¼å…¥ç°æœ‰æ¨¡å—çš„åŠŸèƒ½
from LLM.action_praser import (
    parse_action_to_structure_output,
    parsing_response_to_pyautogui_code,
)
from LLM.uitar import (
    draw_box_and_show,
    run as uitar_run,
    parse_action_output
)
# å¯¼å…¥åæ ‡å·¥å…·
from utils.coordinate_utils import parse_box_coordinates, scale_coordinates_to_absolute

logger = logging.getLogger(__name__)

class AIAutomationService:
    """AIè‡ªåŠ¨åŒ–æœåŠ¡ç±»"""
    
    def __init__(self, ark_api_key: Optional[str] = None, model_name: str = "doubao-1.5-ui-tars-250328"):
        """
        åˆå§‹åŒ–AIè‡ªåŠ¨åŒ–æœåŠ¡
        
        Args:
            ark_api_key: ç«å±±å¼•æ“APIå¯†é’¥ï¼Œå¦‚æœä¸ºNoneåˆ™ä»ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼è·å–
            model_name: ä½¿ç”¨çš„AIæ¨¡å‹åç§°
        """
        self.ark_api_key = ark_api_key or "53008c87-b444-41c2-8515-88db94d60162"
        self.model_name = model_name
        self.image_factor = 28
        self.max_pixels = 16384 * 28 * 28
        self.min_pixels = 100 * 28 * 28
        
        # é…ç½®pyautogui
        pyautogui.FAILSAFE = True
        pyautogui.PAUSE = 0.5
        
        logger.info(f"AIè‡ªåŠ¨åŒ–æœåŠ¡åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å‹: {model_name}")
    
    def analyze_screenshot(self, user_id: int, image_path: str, user_instruction: str, 
                          show_visualization: bool = False, target_resolution: str = "auto") -> Dict[str, Any]:
        """
        åˆ†ææˆªå›¾å¹¶ç”Ÿæˆæ“ä½œæŒ‡ä»¤
        
        Args:
            user_id: å½“å‰æ“ä½œçš„ç”¨æˆ·ID
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            user_instruction: ç”¨æˆ·æŒ‡ä»¤
            show_visualization: æ˜¯å¦æ˜¾ç¤ºå¯è§†åŒ–ç»“æœ
            target_resolution: ç›®æ ‡åˆ†è¾¨ç‡ (æ ¼å¼å¦‚ "1920x1080" æˆ– "auto")
            
        Returns:
            Dict: åŒ…å«åˆ†æç»“æœå’Œæ“ä½œæŒ‡ä»¤çš„å­—å…¸
        """
        try:
            # 1. éªŒè¯å›¾åƒæ–‡ä»¶å¹¶è½¬ä¸ºBase64
            if not os.path.exists(image_path):
                raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            
            with open(image_path, "rb") as f:
                original_screenshot_base64 = image_to_base64(f.read())

            # 2. è·å–å›¾åƒä¿¡æ¯
            image = Image.open(image_path)
            original_width, original_height = image.size
            
            # 3. è°ƒç”¨AIåˆ†æ
            start_time = time.time()
            ai_response = uitar_run(image_path, user_instruction)
            processing_time = int((time.time() - start_time) * 1000)
            
            # 4. è§£æAIè¾“å‡º (ä»…ç”¨äºè·å–åŸå§‹ thought å’Œ action)
            raw_parsed_action = json.loads(parse_action_output(ai_response))
            
            # 5. ç”Ÿæˆç»“æ„åŒ–æ“ä½œ
            structured_actions = self._generate_structured_actions(
                ai_response, original_height, original_width
            )

            # 6. æ ¸å¿ƒåæ ‡å¤„ç†ï¼šè§£æã€ç¼©æ”¾
            self._process_and_scale_coordinates(structured_actions, target_resolution, (original_width, original_height))

            # 7. ç”ŸæˆPyAutoGUIä»£ç 
            pyautogui_code = parsing_response_to_pyautogui_code(structured_actions)
            
            # 8. åˆ›å»ºå¯è§†åŒ–å›¾ç‰‡å¹¶è·å–å…¶Base64
            annotated_screenshot_base64 = self._create_visualization_image_base64(image, structured_actions)
            
            # 9. æ„å»ºè¿”å›ç»“æœ (ç°åœ¨è¿”å›base64)
            result = {
                "success": True,
                "user_id": user_id,
                "user_instruction": user_instruction,
                "target_resolution": target_resolution,
                "image_info": {
                    "path": image_path,
                    "size": (original_width, original_height)
                },
                "ai_response": {
                    "raw_text": ai_response,
                    "processing_time_ms": processing_time
                },
                "parsed_action": raw_parsed_action,
                "structured_actions": structured_actions,
                "pyautogui_code": pyautogui_code,
                "annotated_screenshot_base64": annotated_screenshot_base64,
                "timestamp": time.time()
            }
            
            # 10. ä¿å­˜åˆ†æè®°å½•åˆ°æ•°æ®åº“
            self._save_analysis_log(
                user_id=user_id,
                user_instruction=user_instruction,
                original_screenshot_base64=original_screenshot_base64,
                annotated_screenshot_base64=annotated_screenshot_base64,
                analysis_result=result,
                target_resolution=target_resolution
            )

            logger.info(f"åˆ†æå®Œæˆï¼ŒåŠ¨ä½œç±»å‹: {raw_parsed_action.get('action', 'unknown')}")
            return result
            
        except Exception as e:
            logger.error(f"åˆ†ææˆªå›¾æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "user_id": user_id,
                "user_instruction": user_instruction,
                "timestamp": time.time()
            }
    
    def execute_actions(self, analysis_result: Dict[str, Any], 
                       dry_run: bool = True) -> Dict[str, Any]:
        """
        æ‰§è¡Œåˆ†æå¾—åˆ°çš„æ“ä½œ
        
        Args:
            analysis_result: analyze_screenshotçš„è¿”å›ç»“æœ
            dry_run: æ˜¯å¦ä¸ºæ¼”ç»ƒæ¨¡å¼ï¼ˆä¸å®é™…æ‰§è¡Œæ“ä½œï¼‰
            
        Returns:
            Dict: æ‰§è¡Œç»“æœ
        """
        if not analysis_result.get("success"):
            return {
                "success": False,
                "error": "åˆ†æç»“æœæ— æ•ˆï¼Œæ— æ³•æ‰§è¡Œæ“ä½œ"
            }
        
        try:
            pyautogui_code = analysis_result.get("pyautogui_code", "")
            
            if dry_run:
                logger.info("æ¼”ç»ƒæ¨¡å¼ï¼šä¸å®é™…æ‰§è¡Œæ“ä½œ")
                return {
                    "success": True,
                    "dry_run": True,
                    "code": pyautogui_code,
                    "message": "æ¼”ç»ƒæ¨¡å¼ï¼Œä»£ç å·²å‡†å¤‡ä½†æœªæ‰§è¡Œ"
                }
            
            # å®é™…æ‰§è¡Œä»£ç 
            logger.warning("å³å°†æ‰§è¡Œè‡ªåŠ¨åŒ–æ“ä½œï¼Œè¯·ç¡®ä¿æ¡Œé¢å‡†å¤‡å°±ç»ª...")
            time.sleep(2)  # ç»™ç”¨æˆ·å‡†å¤‡æ—¶é—´
            
            # å®‰å…¨æ£€æŸ¥
            if "DONE" in pyautogui_code:
                return {
                    "success": True,
                    "message": "ä»»åŠ¡å·²å®Œæˆï¼Œæ— éœ€æ‰§è¡Œé¢å¤–æ“ä½œ"
                }
            
            # æ‰§è¡Œä»£ç 
            start_time = time.time()
            exec(pyautogui_code)
            execution_time = int((time.time() - start_time) * 1000)
            
            return {
                "success": True,
                "execution_time_ms": execution_time,
                "code": pyautogui_code,
                "message": "æ“ä½œæ‰§è¡Œå®Œæˆ"
            }
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œæ“ä½œæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def batch_process(self, tasks: List[Dict[str, str]], 
                     execute: bool = False) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡å¤„ç†å¤šä¸ªä»»åŠ¡
        
        Args:
            tasks: ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªä»»åŠ¡åŒ…å« {"image_path": "", "instruction": ""}
            execute: æ˜¯å¦æ‰§è¡Œæ“ä½œ
            
        Returns:
            List[Dict]: æ‰€æœ‰ä»»åŠ¡çš„å¤„ç†ç»“æœ
        """
        results = []
        
        for i, task in enumerate(tasks):
            logger.info(f"å¤„ç†ç¬¬ {i+1}/{len(tasks)} ä¸ªä»»åŠ¡")
            
            # åˆ†æä»»åŠ¡
            analysis_result = self.analyze_screenshot(
                task["user_id"], 
                task["image_path"], 
                task["instruction"]
            )
            
            # æ‰§è¡Œä»»åŠ¡ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if execute and analysis_result.get("success"):
                execution_result = self.execute_actions(analysis_result, dry_run=False)
                analysis_result["execution_result"] = execution_result
                
                # ä»»åŠ¡é—´å»¶è¿Ÿ
                if i < len(tasks) - 1:
                    time.sleep(3)
            
            results.append(analysis_result)
        
        return results
    
    def save_analysis_report(self, analysis_result: Dict[str, Any], 
                           output_path: str = "analysis_report.json") -> bool:
        """
        ä¿å­˜åˆ†ææŠ¥å‘Š
        
        Args:
            analysis_result: åˆ†æç»“æœ
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(analysis_result, f, ensure_ascii=False, indent=2)
            logger.info(f"åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
            return True
        except Exception as e:
            logger.error(f"ä¿å­˜åˆ†ææŠ¥å‘Šå¤±è´¥: {str(e)}")
            return False
    
    def _generate_structured_actions(self, ai_response: str, 
                                   height: int, width: int) -> List[Dict[str, Any]]:
        """ä»AIåŸå§‹å“åº”ç”Ÿæˆç»“æ„åŒ–æ“ä½œ"""
        return parse_action_to_structure_output(
            ai_response,
            factor=1000.0,
            origin_resized_height=height,
            origin_resized_width=width,
            model_type=self.model_name
        )

    def _process_and_scale_coordinates(self, 
                                     actions: List[Dict[str, Any]], 
                                     target_resolution_str: str,
                                     original_img_size: Tuple[int, int]):
        """
        ç»Ÿä¸€å¤„ç†æ‰€æœ‰æ“ä½œçš„åæ ‡è§£æå’Œç¼©æ”¾ã€‚
        è¯¥å‡½æ•°ä¼šç›´æ¥ä¿®æ”¹ `actions` åˆ—è¡¨ä¸­çš„å­—å…¸ã€‚
        """
        # 1. è§£æç›®æ ‡åˆ†è¾¨ç‡
        if target_resolution_str == "auto":
            try:
                target_resolution = pyautogui.size()
            except Exception:
                logger.warning("æ— æ³•è‡ªåŠ¨è·å–å±å¹•åˆ†è¾¨ç‡ï¼Œå°†ä½¿ç”¨æˆªå›¾åŸå§‹åˆ†è¾¨ç‡ã€‚")
                target_resolution = original_img_size
        else:
            try:
                target_w, target_h = map(int, target_resolution_str.split('x'))
                target_resolution = (target_w, target_h)
            except ValueError:
                logger.warning(f"æ— æ•ˆçš„ç›®æ ‡åˆ†è¾¨ç‡æ ¼å¼: {target_resolution_str}ï¼Œå°†ä½¿ç”¨æˆªå›¾åŸå§‹åˆ†è¾¨ç‡ã€‚")
                target_resolution = original_img_size

        # 2. éå†æ‰€æœ‰åŠ¨ä½œï¼Œå¤„ç†åæ ‡
        for action in actions:
            inputs = action.get("action_inputs", {})
            
            # å¤„ç† start_box
            if "start_box" in inputs:
                box_coords = parse_box_coordinates(inputs["start_box"])
                if box_coords:
                    abs_x, abs_y = scale_coordinates_to_absolute(box_coords, target_resolution)
                    inputs["abs_x"] = abs_x
                    inputs["abs_y"] = abs_y
                    # å¯é€‰ï¼šä¸ºæ‹–æ‹½æ“ä½œä¿å­˜èµ·å§‹ç‚¹
                    inputs["start_abs_x"] = abs_x
                    inputs["start_abs_y"] = abs_y

            # å¤„ç† end_box (ç”¨äºæ‹–æ‹½)
            if "end_box" in inputs:
                box_coords = parse_box_coordinates(inputs["end_box"])
                if box_coords:
                    abs_x, abs_y = scale_coordinates_to_absolute(box_coords, target_resolution)
                    # ä¸ºæ‹–æ‹½æ“ä½œä¿å­˜ç»“æŸç‚¹
                    inputs["end_abs_x"] = abs_x
                    inputs["end_abs_y"] = abs_y

    def _create_visualization_image_base64(self, 
                                           original_image: Image.Image, 
                                           actions: List[Dict[str, Any]]) -> Optional[str]:
        """
        åœ¨åŸå§‹æˆªå›¾ä¸Šç»˜åˆ¶æ“ä½œçš„å¯è§†åŒ–æ ‡è®°ï¼Œå¹¶è¿”å›Base64ç¼–ç ã€‚
        """
        if not actions:
            return None

        try:
            # (ä¹‹å‰çš„é€»è¾‘ä¿æŒä¸å˜ï¼Œåªæ˜¯æœ€åä¸ä¿å­˜æ–‡ä»¶è€Œæ˜¯è¿”å›base64)
            target_resolution = original_image.size
            draw_image = original_image.copy()
            draw = ImageDraw.Draw(draw_image)
            action = actions[0]
            inputs = action.get("action_inputs", {})
            box_str = inputs.get("start_box")
            if not box_str: return None
            box_coords = parse_box_coordinates(box_str)
            if not box_coords: return None
            abs_x, abs_y = scale_coordinates_to_absolute(box_coords, target_resolution)
            radius = 15
            box = [abs_x - radius, abs_y - radius, abs_x + radius, abs_y + radius]
            draw.ellipse(box, fill="red", outline="red")
            halo_radius = radius + 7
            halo_box = [abs_x - halo_radius, abs_y - halo_radius, abs_x + halo_radius, abs_y + halo_radius]
            draw.ellipse(halo_box, outline="yellow", width=5)

            # å°†å›¾ç‰‡è½¬æ¢ä¸ºBase64
            img_str = image_to_base64(draw_image)
            
            return img_str

        except Exception as e:
            logger.error(f"åˆ›å»ºå¯è§†åŒ–å›¾ç‰‡Base64å¤±è´¥: {e}")
            return None

    def _save_analysis_log(self, user_id: int, user_instruction: str, 
                           original_screenshot_base64: str, 
                           annotated_screenshot_base64: Optional[str],
                           analysis_result: Dict[str, Any], target_resolution: str):
        """å°†åˆ†æç»“æœä¿å­˜åˆ°æ•°æ®åº“"""
        try:
            log = AnalysisLog(
                user_id=user_id,
                timestamp=datetime.fromtimestamp(analysis_result['timestamp']),
                user_instruction=user_instruction,
                original_screenshot_base64=original_screenshot_base64,
                annotated_screenshot_base64=annotated_screenshot_base64,
                analysis_result_json=json.dumps(analysis_result, ensure_ascii=False, indent=2),
                target_resolution=target_resolution
            )
            log_id = AnalysisLogDAO.add_analysis_log(log)
            if log_id:
                logger.info(f"æˆåŠŸå°†åˆ†æè®°å½•ä¿å­˜åˆ°æ•°æ®åº“ï¼Œæ—¥å¿—ID: {log_id}")
            else:
                logger.warning("ä¿å­˜åˆ†æè®°å½•åˆ°æ•°æ®åº“å¤±è´¥ã€‚")
        except Exception as e:
            logger.error(f"ä¿å­˜åˆ†æè®°å½•åˆ°æ•°æ®åº“æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")


class AIAutomationWorkflow:
    """AIè‡ªåŠ¨åŒ–å·¥ä½œæµç±» - æä¾›æ›´é«˜çº§çš„å°è£…"""
    
    def __init__(self, service: AIAutomationService):
        self.service = service
        self.session_results = []
    
    def run_single_task(self, image_path: str, instruction: str, 
                       auto_execute: bool = False, show_preview: bool = True) -> Dict[str, Any]:
        """
        è¿è¡Œå•ä¸ªè‡ªåŠ¨åŒ–ä»»åŠ¡
        
        Args:
            image_path: æˆªå›¾è·¯å¾„
            instruction: ç”¨æˆ·æŒ‡ä»¤
            auto_execute: æ˜¯å¦è‡ªåŠ¨æ‰§è¡Œ
            show_preview: æ˜¯å¦æ˜¾ç¤ºé¢„è§ˆ
            
        Returns:
            Dict: ä»»åŠ¡æ‰§è¡Œç»“æœ
        """
        print(f"\nğŸ¤– å¼€å§‹åˆ†æä»»åŠ¡ï¼š{instruction}")
        
        # åˆ†ææˆªå›¾
        result = self.service.analyze_screenshot(
            result["user_id"],
            image_path, 
            instruction, 
            show_visualization=show_preview
        )
        
        if not result.get("success"):
            print(f"âŒ åˆ†æå¤±è´¥ï¼š{result.get('error')}")
            return result
        
        # æ˜¾ç¤ºåˆ†æç»“æœ
        action = result["parsed_action"]
        print(f"ğŸ’­ AIæ€è€ƒï¼š{action.get('thought', 'æ— ')}")
        print(f"ğŸ¯ è®¡åˆ’åŠ¨ä½œï¼š{action.get('action', 'æ— ')}")
        
        if action.get("content"):
            print(f"ğŸ“ è¾“å…¥å†…å®¹ï¼š{action.get('content')}")
        
        # æ˜¾ç¤ºç”Ÿæˆçš„ä»£ç 
        code = result.get("pyautogui_code", "")
        if code and code != "# æ— å¯æ‰§è¡Œçš„æ“ä½œ":
            print(f"\nğŸ”§ ç”Ÿæˆçš„æ“ä½œä»£ç ï¼š")
            print("=" * 50)
            print(code)
            print("=" * 50)
        
        # æ˜¯å¦æ‰§è¡Œ
        if auto_execute:
            print("\nâš¡ è‡ªåŠ¨æ‰§è¡Œæ“ä½œ...")
            execution_result = self.service.execute_actions(result, dry_run=False)
            result["execution_result"] = execution_result
            
            if execution_result.get("success"):
                print("âœ… æ“ä½œæ‰§è¡Œå®Œæˆ")
            else:
                print(f"âŒ æ‰§è¡Œå¤±è´¥ï¼š{execution_result.get('error')}")
        else:
            print("\nâ¸ï¸  æ¼”ç»ƒæ¨¡å¼ï¼šæ“ä½œæœªå®é™…æ‰§è¡Œ")
        
        # ä¿å­˜åˆ°ä¼šè¯è®°å½•
        self.session_results.append(result)
        
        return result
    
    def interactive_mode(self):
        """äº¤äº’å¼æ¨¡å¼"""
        print("\nğŸš€ è¿›å…¥AIè‡ªåŠ¨åŒ–äº¤äº’æ¨¡å¼")
        print("è¾“å…¥ 'quit' é€€å‡ºï¼Œ'help' æŸ¥çœ‹å¸®åŠ©")
        
        while True:
            try:
                print("\n" + "-" * 60)
                image_path = input("ğŸ“¸ è¯·è¾“å…¥æˆªå›¾è·¯å¾„ (æˆ–æ‹–æ‹½æ–‡ä»¶): ").strip()
                
                if image_path.lower() == 'quit':
                    break
                elif image_path.lower() == 'help':
                    self._show_help()
                    continue
                
                # æ¸…ç†è·¯å¾„ï¼ˆå¤„ç†æ‹–æ‹½æ–‡ä»¶çš„å¼•å·ï¼‰
                image_path = image_path.strip('"\'')
                
                if not os.path.exists(image_path):
                    print("âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°è¾“å…¥")
                    continue
                
                instruction = input("ğŸ’¬ è¯·è¾“å…¥æ“ä½œæŒ‡ä»¤: ").strip()
                if not instruction:
                    print("âŒ æŒ‡ä»¤ä¸èƒ½ä¸ºç©º")
                    continue
                
                auto_execute = input("âš¡ æ˜¯å¦è‡ªåŠ¨æ‰§è¡Œ? (y/N): ").strip().lower() == 'y'
                
                # æ‰§è¡Œä»»åŠ¡
                self.run_single_task(image_path, instruction, auto_execute)
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
                break
            except Exception as e:
                print(f"âŒ å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
        
        print("ğŸ“Š ä¼šè¯ç»“æŸï¼Œå…±å¤„ç† {} ä¸ªä»»åŠ¡".format(len(self.session_results)))
    
    def _show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        help_text = """
ğŸ†˜ å¸®åŠ©ä¿¡æ¯ï¼š

1. æˆªå›¾è·¯å¾„ï¼šæ”¯æŒç›¸å¯¹è·¯å¾„ã€ç»å¯¹è·¯å¾„ï¼Œå¯ç›´æ¥æ‹–æ‹½æ–‡ä»¶
2. æ“ä½œæŒ‡ä»¤ï¼šç”¨è‡ªç„¶è¯­è¨€æè¿°è¦æ‰§è¡Œçš„æ“ä½œï¼Œä¾‹å¦‚ï¼š
   - "ç‚¹å‡»ç™»å½•æŒ‰é’®"
   - "åœ¨æœç´¢æ¡†è¾“å…¥Python"
   - "æ»šåŠ¨é¡µé¢å‘ä¸‹"
   - "åŒå‡»æ¡Œé¢ä¸Šçš„Chromeå›¾æ ‡"

3. å®‰å…¨æç¤ºï¼š
   - å»ºè®®å…ˆä¸æ‰§è¡Œï¼ŒæŸ¥çœ‹ç”Ÿæˆçš„ä»£ç æ˜¯å¦æ­£ç¡®
   - ç¡®ä¿æ¡Œé¢ç¯å¢ƒä¸æˆªå›¾ä¸€è‡´
   - é‡è¦æ“ä½œå‰è¯·å¤‡ä»½æ•°æ®

4. å‘½ä»¤ï¼š
   - quit: é€€å‡ºç¨‹åº
   - help: æ˜¾ç¤ºæ­¤å¸®åŠ©
        """
        print(help_text)


# ä¾¿æ·å‡½æ•°
def quick_automation(image_path: str, instruction: str, 
                    execute: bool = False, show_preview: bool = True) -> Dict[str, Any]:
    """
    å¿«é€Ÿè‡ªåŠ¨åŒ–å‡½æ•°
    
    Args:
        image_path: æˆªå›¾è·¯å¾„
        instruction: æ“ä½œæŒ‡ä»¤
        execute: æ˜¯å¦æ‰§è¡Œæ“ä½œ
        show_preview: æ˜¯å¦æ˜¾ç¤ºé¢„è§ˆ
        
    Returns:
        Dict: æ“ä½œç»“æœ
    """
    service = AIAutomationService()
    workflow = AIAutomationWorkflow(service)
    return workflow.run_single_task(image_path, instruction, execute, show_preview)


if __name__ == "__main__":
    # æ¼”ç¤ºç”¨æ³•
    import sys
    
    if len(sys.argv) > 1:
        # å‘½ä»¤è¡Œæ¨¡å¼
        if len(sys.argv) >= 3:
            image_path = sys.argv[1]
            instruction = sys.argv[2]
            execute = len(sys.argv) > 3 and sys.argv[3].lower() == 'true'
            
            result = quick_automation(image_path, instruction, execute)
            print(f"\nç»“æœï¼š{result.get('success', False)}")
        else:
            print("ç”¨æ³•: python ai_automation_service.py <image_path> <instruction> [execute]")
    else:
        # äº¤äº’å¼æ¨¡å¼
        service = AIAutomationService()
        workflow = AIAutomationWorkflow(service)
        workflow.interactive_mode() 