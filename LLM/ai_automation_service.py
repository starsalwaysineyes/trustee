"""
AIè‡ªåŠ¨åŒ–æœåŠ¡
æ•´åˆå›¾åƒè¯†åˆ«ã€AIåˆ†æã€åŠ¨ä½œè§£æå’Œä»£ç ç”Ÿæˆçš„å®Œæ•´å·¥ä½œæµ
"""

import os
import time
import json
import logging
from typing import Dict, Any, List, Optional, Tuple
from PIL import Image
import pyautogui
import pyperclip

# å¯¼å…¥ç°æœ‰æ¨¡å—çš„åŠŸèƒ½ï¼Œæ·»åŠ é”™è¯¯å¤„ç†
try:
    try:
        from .uitar import (
            image_to_base64, 
            parse_action_output, 
            coordinates_convert, 
            draw_box_and_show,
            run as uitar_run
        )
        from .action_praser import (
            parse_action_to_structure_output,
            parsing_response_to_pyautogui_code,
            smart_resize,
            linear_resize
        )
    except ImportError:
        from uitar import (
            image_to_base64, 
            parse_action_output, 
            coordinates_convert, 
            draw_box_and_show,
            run as uitar_run
        )
        from action_praser import (
            parse_action_to_structure_output,
            parsing_response_to_pyautogui_code,
            smart_resize,
            linear_resize
        )
except ImportError as e:
    # å¦‚æœæ¨¡å—ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ¨¡æ‹Ÿå‡½æ•°
    def uitar_run(image_path, instruction):
        return f'{{"thought": "æ¨¡æ‹ŸAIåˆ†æ: {instruction}", "action": "click", "start_box": "[100, 100, 200, 200]"}}'
    
    def parse_action_output(response):
        return response
    
    def coordinates_convert(box, image_size):
        return [100, 100, 200, 200]
    
    def draw_box_and_show(image, start_abs, end_abs, direction):
        pass
    
    def parse_action_to_structure_output(*args, **kwargs):
        return [{"action_type": "click", "action_inputs": {"start_box": "[0.1, 0.1, 0.2, 0.2]"}}]
    
    def parsing_response_to_pyautogui_code(actions, *args, **kwargs):
        return "# æ¨¡æ‹Ÿä»£ç \nimport pyautogui\npyautogui.click(150, 150)"
    
    def smart_resize(height, width, *args, **kwargs):
        return height, width
    
    def linear_resize(height, width, *args, **kwargs):
        return height, width

logger = logging.getLogger(__name__)

class AIAutomationService:
    """AIè‡ªåŠ¨åŒ–æœåŠ¡ç±»"""
    
    def __init__(self, ark_api_key: Optional[str] = None, model_name: str = "doubao-1.5-ui-tars-250328"):
        """
        åˆå§‹åŒ–AIè‡ªåŠ¨åŒ–æœåŠ¡
        
        Args:
            ark_api_key: ç«å±±å¼•æ“APIå¯†é’¥ï¼Œå¦‚æœä¸ºNoneåˆ™ä»ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼è·å–
            model_name: ä½¿ç”¨çš„AIæ¨¡å‹åç§°
        """
        self.ark_api_key = ark_api_key or "53008c87-b444-41c2-8515-88db94d60162"
        self.model_name = model_name
        self.image_factor = 28
        self.max_pixels = 16384 * 28 * 28
        self.min_pixels = 100 * 28 * 28
        
        # é…ç½®pyautogui
        pyautogui.FAILSAFE = True
        pyautogui.PAUSE = 0.5
        
        logger.info(f"AIè‡ªåŠ¨åŒ–æœåŠ¡åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å‹: {model_name}")
    
    def analyze_screenshot(self, image_path: str, user_instruction: str, 
                          show_visualization: bool = False) -> Dict[str, Any]:
        """
        åˆ†ææˆªå›¾å¹¶ç”Ÿæˆæ“ä½œæŒ‡ä»¤
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            user_instruction: ç”¨æˆ·æŒ‡ä»¤
            show_visualization: æ˜¯å¦æ˜¾ç¤ºå¯è§†åŒ–ç»“æœ
            
        Returns:
            Dict: åŒ…å«åˆ†æç»“æœå’Œæ“ä½œæŒ‡ä»¤çš„å­—å…¸
        """
        try:
            # 1. éªŒè¯å›¾åƒæ–‡ä»¶
            if not os.path.exists(image_path):
                raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            
            # 2. è·å–å›¾åƒä¿¡æ¯
            image = Image.open(image_path)
            original_width, original_height = image.size
            
            # 3. è°ƒç”¨AIåˆ†æ
            start_time = time.time()
            ai_response = uitar_run(image_path, user_instruction)
            processing_time = int((time.time() - start_time) * 1000)
            
            # 4. è§£æAIè¾“å‡º
            parsed_action = json.loads(parse_action_output(ai_response))
            
            # 5. è½¬æ¢åæ ‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            converted_actions = []
            if parsed_action.get("start_box"):
                start_abs = coordinates_convert(parsed_action["start_box"], image.size)
                parsed_action["start_box_abs"] = start_abs
            
            if parsed_action.get("end_box"):
                end_abs = coordinates_convert(parsed_action["end_box"], image.size)
                parsed_action["end_box_abs"] = end_abs
            
            # 6. ç”Ÿæˆç»“æ„åŒ–è¾“å‡º
            structured_actions = self._generate_structured_actions(
                ai_response, original_height, original_width
            )
            
            # 7. ç”ŸæˆPyAutoGUIä»£ç 
            pyautogui_code = self._generate_pyautogui_code(
                structured_actions, original_height, original_width
            )
            
            # 8. å¯è§†åŒ–ç»“æœï¼ˆå¯é€‰ï¼‰
            if show_visualization:
                self._show_visualization(image, parsed_action)
            
            # 9. æ„å»ºè¿”å›ç»“æœ
            result = {
                "success": True,
                "user_instruction": user_instruction,
                "image_info": {
                    "path": image_path,
                    "size": (original_width, original_height)
                },
                "ai_response": {
                    "raw_text": ai_response,
                    "processing_time_ms": processing_time
                },
                "parsed_action": parsed_action,
                "structured_actions": structured_actions,
                "pyautogui_code": pyautogui_code,
                "timestamp": time.time()
            }
            
            logger.info(f"åˆ†æå®Œæˆï¼ŒåŠ¨ä½œç±»å‹: {parsed_action.get('action', 'unknown')}")
            return result
            
        except Exception as e:
            logger.error(f"åˆ†ææˆªå›¾æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "user_instruction": user_instruction,
                "timestamp": time.time()
            }
    
    def execute_actions(self, analysis_result: Dict[str, Any], 
                       dry_run: bool = True) -> Dict[str, Any]:
        """
        æ‰§è¡Œåˆ†æå¾—åˆ°çš„æ“ä½œ
        
        Args:
            analysis_result: analyze_screenshotçš„è¿”å›ç»“æœ
            dry_run: æ˜¯å¦ä¸ºæ¼”ç»ƒæ¨¡å¼ï¼ˆä¸å®é™…æ‰§è¡Œæ“ä½œï¼‰
            
        Returns:
            Dict: æ‰§è¡Œç»“æœ
        """
        if not analysis_result.get("success"):
            return {
                "success": False,
                "error": "åˆ†æç»“æœæ— æ•ˆï¼Œæ— æ³•æ‰§è¡Œæ“ä½œ"
            }
        
        try:
            pyautogui_code = analysis_result.get("pyautogui_code", "")
            
            if dry_run:
                logger.info("æ¼”ç»ƒæ¨¡å¼ï¼šä¸å®é™…æ‰§è¡Œæ“ä½œ")
                return {
                    "success": True,
                    "dry_run": True,
                    "code": pyautogui_code,
                    "message": "æ¼”ç»ƒæ¨¡å¼ï¼Œä»£ç å·²å‡†å¤‡ä½†æœªæ‰§è¡Œ"
                }
            
            # å®é™…æ‰§è¡Œä»£ç 
            logger.warning("å³å°†æ‰§è¡Œè‡ªåŠ¨åŒ–æ“ä½œï¼Œè¯·ç¡®ä¿æ¡Œé¢å‡†å¤‡å°±ç»ª...")
            time.sleep(2)  # ç»™ç”¨æˆ·å‡†å¤‡æ—¶é—´
            
            # å®‰å…¨æ£€æŸ¥
            if "DONE" in pyautogui_code:
                return {
                    "success": True,
                    "message": "ä»»åŠ¡å·²å®Œæˆï¼Œæ— éœ€æ‰§è¡Œé¢å¤–æ“ä½œ"
                }
            
            # æ‰§è¡Œä»£ç 
            start_time = time.time()
            exec(pyautogui_code)
            execution_time = int((time.time() - start_time) * 1000)
            
            return {
                "success": True,
                "execution_time_ms": execution_time,
                "code": pyautogui_code,
                "message": "æ“ä½œæ‰§è¡Œå®Œæˆ"
            }
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œæ“ä½œæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def batch_process(self, tasks: List[Dict[str, str]], 
                     execute: bool = False) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡å¤„ç†å¤šä¸ªä»»åŠ¡
        
        Args:
            tasks: ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªä»»åŠ¡åŒ…å« {"image_path": "", "instruction": ""}
            execute: æ˜¯å¦æ‰§è¡Œæ“ä½œ
            
        Returns:
            List[Dict]: æ‰€æœ‰ä»»åŠ¡çš„å¤„ç†ç»“æœ
        """
        results = []
        
        for i, task in enumerate(tasks):
            logger.info(f"å¤„ç†ç¬¬ {i+1}/{len(tasks)} ä¸ªä»»åŠ¡")
            
            # åˆ†æä»»åŠ¡
            analysis_result = self.analyze_screenshot(
                task["image_path"], 
                task["instruction"]
            )
            
            # æ‰§è¡Œä»»åŠ¡ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if execute and analysis_result.get("success"):
                execution_result = self.execute_actions(analysis_result, dry_run=False)
                analysis_result["execution_result"] = execution_result
                
                # ä»»åŠ¡é—´å»¶è¿Ÿ
                if i < len(tasks) - 1:
                    time.sleep(3)
            
            results.append(analysis_result)
        
        return results
    
    def save_analysis_report(self, analysis_result: Dict[str, Any], 
                           output_path: str = "analysis_report.json") -> bool:
        """
        ä¿å­˜åˆ†ææŠ¥å‘Š
        
        Args:
            analysis_result: åˆ†æç»“æœ
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(analysis_result, f, ensure_ascii=False, indent=2)
            logger.info(f"åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
            return True
        except Exception as e:
            logger.error(f"ä¿å­˜åˆ†ææŠ¥å‘Šå¤±è´¥: {str(e)}")
            return False
    
    def _generate_structured_actions(self, ai_response: str, 
                                   height: int, width: int) -> List[Dict[str, Any]]:
        """ç”Ÿæˆç»“æ„åŒ–çš„åŠ¨ä½œåˆ—è¡¨"""
        try:
            # è®¡ç®—è°ƒæ•´åçš„å›¾åƒå°ºå¯¸
            resized_height, resized_width = smart_resize(
                height, width, 
                factor=self.image_factor,
                min_pixels=self.min_pixels,
                max_pixels=self.max_pixels
            )
            
            # è§£æåŠ¨ä½œ
            actions = parse_action_to_structure_output(
                ai_response,
                factor=self.image_factor,
                origin_resized_height=resized_height,
                origin_resized_width=resized_width,
                model_type="qwen25vl",
                max_pixels=self.max_pixels,
                min_pixels=self.min_pixels
            )
            
            return actions
        except Exception as e:
            logger.error(f"ç”Ÿæˆç»“æ„åŒ–åŠ¨ä½œå¤±è´¥: {str(e)}")
            return []
    
    def _generate_pyautogui_code(self, structured_actions: List[Dict[str, Any]], 
                               height: int, width: int) -> str:
        """ç”ŸæˆPyAutoGUIä»£ç """
        try:
            if not structured_actions:
                return "# æ— å¯æ‰§è¡Œçš„æ“ä½œ"
            
            code = parsing_response_to_pyautogui_code(
                structured_actions, 
                image_height=height,
                image_width=width,
                input_swap=True
            )
            
            return code
        except Exception as e:
            logger.error(f"ç”ŸæˆPyAutoGUIä»£ç å¤±è´¥: {str(e)}")
            return f"# ä»£ç ç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def _show_visualization(self, image: Image.Image, parsed_action: Dict[str, Any]):
        """æ˜¾ç¤ºå¯è§†åŒ–ç»“æœ"""
        try:
            start_abs = parsed_action.get("start_box_abs")
            end_abs = parsed_action.get("end_box_abs")
            direction = parsed_action.get("direction")
            
            draw_box_and_show(image, start_abs, end_abs, direction)
        except Exception as e:
            logger.warning(f"æ˜¾ç¤ºå¯è§†åŒ–ç»“æœå¤±è´¥: {str(e)}")


class AIAutomationWorkflow:
    """AIè‡ªåŠ¨åŒ–å·¥ä½œæµç±» - æä¾›æ›´é«˜çº§çš„å°è£…"""
    
    def __init__(self, service: AIAutomationService):
        self.service = service
        self.session_results = []
    
    def run_single_task(self, image_path: str, instruction: str, 
                       auto_execute: bool = False, show_preview: bool = True) -> Dict[str, Any]:
        """
        è¿è¡Œå•ä¸ªè‡ªåŠ¨åŒ–ä»»åŠ¡
        
        Args:
            image_path: æˆªå›¾è·¯å¾„
            instruction: ç”¨æˆ·æŒ‡ä»¤
            auto_execute: æ˜¯å¦è‡ªåŠ¨æ‰§è¡Œ
            show_preview: æ˜¯å¦æ˜¾ç¤ºé¢„è§ˆ
            
        Returns:
            Dict: ä»»åŠ¡æ‰§è¡Œç»“æœ
        """
        print(f"\nğŸ¤– å¼€å§‹åˆ†æä»»åŠ¡ï¼š{instruction}")
        
        # åˆ†ææˆªå›¾
        result = self.service.analyze_screenshot(
            image_path, instruction, show_visualization=show_preview
        )
        
        if not result.get("success"):
            print(f"âŒ åˆ†æå¤±è´¥ï¼š{result.get('error')}")
            return result
        
        # æ˜¾ç¤ºåˆ†æç»“æœ
        action = result["parsed_action"]
        print(f"ğŸ’­ AIæ€è€ƒï¼š{action.get('thought', 'æ— ')}")
        print(f"ğŸ¯ è®¡åˆ’åŠ¨ä½œï¼š{action.get('action', 'æ— ')}")
        
        if action.get("content"):
            print(f"ğŸ“ è¾“å…¥å†…å®¹ï¼š{action.get('content')}")
        
        # æ˜¾ç¤ºç”Ÿæˆçš„ä»£ç 
        code = result.get("pyautogui_code", "")
        if code and code != "# æ— å¯æ‰§è¡Œçš„æ“ä½œ":
            print(f"\nğŸ”§ ç”Ÿæˆçš„æ“ä½œä»£ç ï¼š")
            print("=" * 50)
            print(code)
            print("=" * 50)
        
        # æ˜¯å¦æ‰§è¡Œ
        if auto_execute:
            print("\nâš¡ è‡ªåŠ¨æ‰§è¡Œæ“ä½œ...")
            execution_result = self.service.execute_actions(result, dry_run=False)
            result["execution_result"] = execution_result
            
            if execution_result.get("success"):
                print("âœ… æ“ä½œæ‰§è¡Œå®Œæˆ")
            else:
                print(f"âŒ æ‰§è¡Œå¤±è´¥ï¼š{execution_result.get('error')}")
        else:
            print("\nâ¸ï¸  æ¼”ç»ƒæ¨¡å¼ï¼šæ“ä½œæœªå®é™…æ‰§è¡Œ")
        
        # ä¿å­˜åˆ°ä¼šè¯è®°å½•
        self.session_results.append(result)
        
        return result
    
    def interactive_mode(self):
        """äº¤äº’å¼æ¨¡å¼"""
        print("\nğŸš€ è¿›å…¥AIè‡ªåŠ¨åŒ–äº¤äº’æ¨¡å¼")
        print("è¾“å…¥ 'quit' é€€å‡ºï¼Œ'help' æŸ¥çœ‹å¸®åŠ©")
        
        while True:
            try:
                print("\n" + "-" * 60)
                image_path = input("ğŸ“¸ è¯·è¾“å…¥æˆªå›¾è·¯å¾„ (æˆ–æ‹–æ‹½æ–‡ä»¶): ").strip()
                
                if image_path.lower() == 'quit':
                    break
                elif image_path.lower() == 'help':
                    self._show_help()
                    continue
                
                # æ¸…ç†è·¯å¾„ï¼ˆå¤„ç†æ‹–æ‹½æ–‡ä»¶çš„å¼•å·ï¼‰
                image_path = image_path.strip('"\'')
                
                if not os.path.exists(image_path):
                    print("âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°è¾“å…¥")
                    continue
                
                instruction = input("ğŸ’¬ è¯·è¾“å…¥æ“ä½œæŒ‡ä»¤: ").strip()
                if not instruction:
                    print("âŒ æŒ‡ä»¤ä¸èƒ½ä¸ºç©º")
                    continue
                
                auto_execute = input("âš¡ æ˜¯å¦è‡ªåŠ¨æ‰§è¡Œ? (y/N): ").strip().lower() == 'y'
                
                # æ‰§è¡Œä»»åŠ¡
                self.run_single_task(image_path, instruction, auto_execute)
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
                break
            except Exception as e:
                print(f"âŒ å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
        
        print("ğŸ“Š ä¼šè¯ç»“æŸï¼Œå…±å¤„ç† {} ä¸ªä»»åŠ¡".format(len(self.session_results)))
    
    def _show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        help_text = """
ğŸ†˜ å¸®åŠ©ä¿¡æ¯ï¼š

1. æˆªå›¾è·¯å¾„ï¼šæ”¯æŒç›¸å¯¹è·¯å¾„ã€ç»å¯¹è·¯å¾„ï¼Œå¯ç›´æ¥æ‹–æ‹½æ–‡ä»¶
2. æ“ä½œæŒ‡ä»¤ï¼šç”¨è‡ªç„¶è¯­è¨€æè¿°è¦æ‰§è¡Œçš„æ“ä½œï¼Œä¾‹å¦‚ï¼š
   - "ç‚¹å‡»ç™»å½•æŒ‰é’®"
   - "åœ¨æœç´¢æ¡†è¾“å…¥Python"
   - "æ»šåŠ¨é¡µé¢å‘ä¸‹"
   - "åŒå‡»æ¡Œé¢ä¸Šçš„Chromeå›¾æ ‡"

3. å®‰å…¨æç¤ºï¼š
   - å»ºè®®å…ˆä¸æ‰§è¡Œï¼ŒæŸ¥çœ‹ç”Ÿæˆçš„ä»£ç æ˜¯å¦æ­£ç¡®
   - ç¡®ä¿æ¡Œé¢ç¯å¢ƒä¸æˆªå›¾ä¸€è‡´
   - é‡è¦æ“ä½œå‰è¯·å¤‡ä»½æ•°æ®

4. å‘½ä»¤ï¼š
   - quit: é€€å‡ºç¨‹åº
   - help: æ˜¾ç¤ºæ­¤å¸®åŠ©
        """
        print(help_text)


# ä¾¿æ·å‡½æ•°
def quick_automation(image_path: str, instruction: str, 
                    execute: bool = False, show_preview: bool = True) -> Dict[str, Any]:
    """
    å¿«é€Ÿè‡ªåŠ¨åŒ–å‡½æ•°
    
    Args:
        image_path: æˆªå›¾è·¯å¾„
        instruction: æ“ä½œæŒ‡ä»¤
        execute: æ˜¯å¦æ‰§è¡Œæ“ä½œ
        show_preview: æ˜¯å¦æ˜¾ç¤ºé¢„è§ˆ
        
    Returns:
        Dict: æ“ä½œç»“æœ
    """
    service = AIAutomationService()
    workflow = AIAutomationWorkflow(service)
    return workflow.run_single_task(image_path, instruction, execute, show_preview)


if __name__ == "__main__":
    # æ¼”ç¤ºç”¨æ³•
    import sys
    
    if len(sys.argv) > 1:
        # å‘½ä»¤è¡Œæ¨¡å¼
        if len(sys.argv) >= 3:
            image_path = sys.argv[1]
            instruction = sys.argv[2]
            execute = len(sys.argv) > 3 and sys.argv[3].lower() == 'true'
            
            result = quick_automation(image_path, instruction, execute)
            print(f"\nç»“æœï¼š{result.get('success', False)}")
        else:
            print("ç”¨æ³•: python ai_automation_service.py <image_path> <instruction> [execute]")
    else:
        # äº¤äº’å¼æ¨¡å¼
        service = AIAutomationService()
        workflow = AIAutomationWorkflow(service)
        workflow.interactive_mode() 